---
title: 'INFO Blog 1: Censorship of Misinformation and Freedom of Speech on Social Media'
date: 2025-11-10
permalink: /posts/2025/11/info-blog-post-1/
tags:
    - censorship
    - Free Speech
    - Society
---

**News Article:**
[Censorship of Misinformation and Freedom of Speech on Social Media](https://mit-serc.pubpub.org/pub/lkf63cu5/release/1)

Case Study Summary
---
The case study talks about how people often want social media companies to censor misinformation, but that might not always be the right answer. The author says misinformation is more of a social problem than a technology problem. It started when people began losing trust in experts, media, and even one another. Censorship might make people feel even more divided instead of fixing the issue.

Looking at these discussion questions
---
My Response to Q1: One example that comes to mind is artificial intelligence. AI can generate wrong or misleading information even when it does not mean to. For instance, some chatbots or image generators can make up facts or show false events that look real. It does not come from a place of harm, but it still spreads misinformation because people might believe what the AI says without checking. I have seen it happen online where people post AI generated images or text thinking it is true, and others share it even more. It shows that misinformation does not always have to come from bad people, it can come from the tools we use.

My response to Q2: When I think about institutions that help share reliable information, the first one that comes to mind is the news. Growing up, I always thought the news told the truth and that everything they said was based on facts. As I have gotten older, I realized it is more complicated than that. The news can still be useful for learning about what is going on in the world, but there is also a lot of bias depending on which network you watch. Some stations sound like they are just defending one side, while others do the same for the opposite side. It makes it harder to know what is actually true. I also think the news is becoming outdated, at least on television. I do not really sit down to watch it anymore. Most of the news I see now comes from social media, which can be good for quick updates but also spreads misinformation even faster.

My response to Q5: Honestly, not much. Most of what I know comes from things I have been taught or read somewhere. I can trust what I see or experience in my own life, like how I feel or what happens around me, but everything beyond that usually depends on other people. For example, I can believe the Earth is round because scientists have proven it, but I could never prove that myself. I think the case study is right that being informed is a social process. We all depend on experts, teachers, and systems that gather information for us, which means we need to trust the right people.

My response to Q6: One thing that helps me is to check where the information comes from. If something sounds strange or too good to be true, I look it up somewhere else to see if other sources agree. I also try not to share things too fast, even if they sound interesting. Sometimes I will ask someone I know if they have heard the same thing or if it sounds reliable. I have learned that just because something makes me feel emotional or fits what I already believe, that does not mean it is true. Slowing down and thinking before reacting makes a big difference.

New Discussion Question:
---
If social media companies stopped moderating content completely, would people be able to handle that level of freedom responsibly? Why or why not?

I came up with this question because the article starts with Elon Musk saying “the bird is freed,” which made me think about what total freedom on the internet would look like. I think everyone likes the idea of free speech, but when there are no rules at all, people can misuse it and hurt others. I wanted to ask this question because it makes people think about the balance between freedom and responsibility, especially on platforms that reach millions of people.

Reflection:
---
Reading this case study made me see how complex misinformation really is. It is not just about deleting false posts or blocking people. It is about rebuilding trust in the systems that give us information. I used to think censoring was the easiest way to stop lies, but now I understand it can sometimes make things worse. If people already do not trust the media or experts, censoring them only adds to that distrust. This made me realize that being informed is not about knowing everything myself, but about learning who and what to trust.

